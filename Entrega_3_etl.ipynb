{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcY9y56n86vn"
   },
   "source": [
    "# Tutorial: creación de ETLs con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcg5UCbU86vp"
   },
   "source": [
    "## 1. Introducción\t\n",
    "    ¿Qué aprenderá?\n",
    "\tEn este tutorial aprenderá cómo puede utilizar PySpark para crear un proceso de ETL básico.\n",
    "\n",
    "\t¿Qué construirá?     \n",
    "        Construirá un ETL que toma los datos desde la base de datos transacional de WideWorldImporters (WWImportersTransactional), los transforma  a una representación cercana al análisis y los  almacena en la base de datos relacional WWImportersDWH.\n",
    "    \n",
    "\t¿Para qué?\n",
    "\tLa construcción de ETLs que se ajusten a modelos multidimensionales es un paso necesario dentro de un proceso de analìtica 1.0 , pues permite tomar los datos crudos de una fuente, generalmente transaccional, para transformarlos en datos limpios que puedan utilizarse para la toma de decisiones.\n",
    "    \n",
    "    ¿Qué necesita?\n",
    "    1. Python 3 con pip instalado\n",
    "    2. Jupyter notebook\n",
    "    3. Paquetes: Pyspark (3.0.1) y pandas (1.2.1)\n",
    "    4. Controlador Connector J de MySQL (ya se encuentra instalado)\n",
    "    5. Servidor SQL con base de datos relacional \"WWImportersTransactional\" y base de datos relacional que corresponde a la bodega de WWI \"Estudiante_i\"\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqQVz5s686vq"
   },
   "source": [
    "## 2. Proceso de ETL para una dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2UT2Ia586vr"
   },
   "source": [
    "En este proceso de ETL, se extraen los datos de las **órdenes de compra** de una base de datos transaccional y se almacenan en otra base de datos que corresponde a la bodega de datos, siguiendo una aproximación ROLAP. A continuación, se presenta el modelo multidimensional que es el modelo conceptual que representa el proceso de registro de órdenes de compra. Este modelo se utilizó para crear las tablas en la bodega de datos que representan el proceso de negocio y que serán cargadas como resultado del proceso ETL. \n",
    "\n",
    "Tenga en cuenta que las llaves ID_XXXX presentes en el modelo hacen referencia a las llaves de la bodega. Por otra parte, en el proceso de ETL se van a tener en cuenta las llaves transaccionales (**WWImportersTransactional**). La nomenclatura para utilizar es:\n",
    "\n",
    "1.   ID_XXXX_DWH, para las llaves de la bodega.\n",
    "2.   ID_XXXX_T, para las llaves transaccionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpOSEfhX86vs"
   },
   "source": [
    "![Modelo ordenes](./WWI_modelo_ordenes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rg1M_rdU86vs"
   },
   "source": [
    "El proceso de ETL debe ser diseñado antes de implementarse. A partir de las conclusiones del entendimiento de datos sabemos las fuentes que se van a  utilizar y la relación entre las fuentes. Adicionalmente, se cuenta con las respuestas de la organización a las preguntas, resultado del entendimiento de datos. De esa manera sabemos cómo se deben manipular los datos. \n",
    "\n",
    "Este proceso de ETL lo dividimos en seis bloques, uno para cada dimensión o <i>tabla de hechos</i> del modelo, con la única excepción de la dimensión de fecha que, por ser una dimensión especial que se genera de forma independiente, no se incluye aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIa8WW1M86vt"
   },
   "source": [
    "![ETL](./Disenio_ETL.PNG)\n",
    "\n",
    "Recuerde que este es el diseño general. En el diseño completo se deben incluir las transformaciones realizadas a los datos a utilizarse en las dimensiones y tablas de hecho del modelo multidimensional, de acuerdo con lo que se muestra en la infografía de arquitectura de componentes (Componente proceso ETL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "os1iJYmu86vt"
   },
   "outputs": [],
   "source": [
    "# Configuración servidor base de datos transaccional\n",
    "# Recuerde usar Estudiante_i como usuario y la contraseña asigana en el excel de conexión a maquina virtual como contraseña\n",
    "db_user = ''\n",
    "db_psswd = ''\n",
    "source_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/WWImportersTransactional'\n",
    "\n",
    "dest_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/Estudiante_58_202413'\n",
    "\n",
    "# Driver de conexion\n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HAGk_V1986vu"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from pyspark.sql import functions as f, SparkSession, types as t\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import udf, col, length, isnan, when, count, regexp_replace, upper, min as min_, unix_timestamp, to_timestamp , from_unixtime, date_format, weekofyear, to_date, year\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TQ3DM_Xf86vv",
    "outputId": "f2cdb157-a92d-4edc-a174-6f3bd09b9885"
   },
   "outputs": [],
   "source": [
    "#Configuración de la sesión\n",
    "spark.stop()\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
    "\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buA7s-vL86vw"
   },
   "source": [
    "### Conexión y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_QZ-j9q86vw"
   },
   "source": [
    "Se define la función para conexión y cargue de dataframes desde la base de datos origen y luego la función para guardar un dataframe en una tabla de la base de datos destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Mhy0jbh_86vw"
   },
   "outputs": [],
   "source": [
    "def obterner_dataframe_desde_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')\n",
    "\n",
    "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
    "    df_bd = spark.read.format('jdbc')\\\n",
    "        .option('url', db_connection_string) \\\n",
    "        .option('dbtable', sql) \\\n",
    "        .option('user', db_user) \\\n",
    "        .option('password', db_psswd) \\\n",
    "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "        .load()\n",
    "    return df_bd\n",
    "\n",
    "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
    "    df.select('*').write.format('jdbc') \\\n",
    "      .mode('append') \\\n",
    "      .option('url', db_connection_string) \\\n",
    "      .option('dbtable', tabla) \\\n",
    "      .option('user', db_user) \\\n",
    "      .option('password', db_psswd) \\\n",
    "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhFsv4ba86vw"
   },
   "source": [
    "### BLOQUE 1\n",
    "Empezamos con el bloque 1: la dimensión <i>TipoTransaccion</i>, su fuente de datos viene de la tabla transaccional <i>TiposTransaccion</i>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNKxFA-f86vx"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "IopBNYuc86vx",
    "outputId": "0589f8a9-527e-4b28-d096-a176efd48e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|ID_Tipo_transaccion|                Tipo|\n",
      "+-------------------+--------------------+\n",
      "|                  2|Customer Credit Note|\n",
      "|                  3|Customer Payment ...|\n",
      "|                  4|     Customer Refund|\n",
      "|                  5|    Supplier Invoice|\n",
      "|                  6|Supplier Credit Note|\n",
      "|                  7|Supplier Payment ...|\n",
      "|                  8|     Supplier Refund|\n",
      "|                  9|      Stock Transfer|\n",
      "|                 10|         Stock Issue|\n",
      "|                 11|       Stock Receipt|\n",
      "+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_tt = '''(SELECT DISTINCT `TipoTransaccionID` AS ID_Tipo_transaccion, `TipoTransaccionNombre` AS Tipo  FROM WWImportersTransactional.TiposTransaccion) AS Temp_tt'''\n",
    "tt = obtener_dataframe_de_bd(source_db_connection_string, sql_tt, db_user, db_psswd)\n",
    "tt.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtE61qk986vx"
   },
   "source": [
    "#### Transformación\n",
    "Recuerde que, puede hacer uso de selectExpr, filter, where entre otras de PySpark para modificar los datos cargados. Por ejemplo, el siguiente código utiliza <i>selectExpr</i> para renombrar la columna ID_Empleado por ID_Empleado_T, esta es la convención que vamos a utilizar: \"_T\" para indicar que el ID es el que estaba en la base de datos transaccional y \"_DWH\" para indicar que son ID's propios de la bodega. Usamos withColumn y monotonicallu_increasing_id para crear un ID acumulativo para cada registro en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------------------+--------------------+\n",
      "|ID_Tipo_transaccion_DWH|ID_Tipo_transaccion_T|                Tipo|\n",
      "+-----------------------+---------------------+--------------------+\n",
      "|                      1|                    2|Customer Credit Note|\n",
      "|                      2|                    3|Customer Payment ...|\n",
      "|                      3|                    4|     Customer Refund|\n",
      "|                      4|                    5|    Supplier Invoice|\n",
      "|                      5|                    6|Supplier Credit Note|\n",
      "|                      6|                    7|Supplier Payment ...|\n",
      "|                      7|                    8|     Supplier Refund|\n",
      "|                      8|                    9|      Stock Transfer|\n",
      "|                      9|                   10|         Stock Issue|\n",
      "|                     10|                   11|       Stock Receipt|\n",
      "|                     11|                   12|Stock Adjustment ...|\n",
      "|                     12|                   13|     Customer Contra|\n",
      "+-----------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombro columnas y creo ID_Tipo_transaccion_DWH\n",
    "tt = tt.selectExpr('ID_Tipo_transaccion as ID_Tipo_transaccion_T','Tipo')\n",
    "tt = tt.coalesce(1).withColumn('ID_Tipo_transaccion_DWH', f.monotonically_increasing_id() + 1)\n",
    "tt = tt.select('ID_Tipo_transaccion_DWH','ID_Tipo_transaccion_T','Tipo')\n",
    "tt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------------------+--------------------+\n",
      "|ID_Tipo_transaccion_DWH|ID_Tipo_transaccion_T|                Tipo|\n",
      "+-----------------------+---------------------+--------------------+\n",
      "|                      1|                    2|Customer Credit Note|\n",
      "|                      2|                    3|Customer Payment ...|\n",
      "|                      3|                    4|     Customer Refund|\n",
      "|                      4|                    5|    Supplier Invoice|\n",
      "|                      5|                    6|Supplier Credit Note|\n",
      "|                      6|                    7|Supplier Payment ...|\n",
      "|                      7|                    8|     Supplier Refund|\n",
      "|                      8|                    9|      Stock Transfer|\n",
      "|                      9|                   10|         Stock Issue|\n",
      "|                     10|                   11|       Stock Receipt|\n",
      "|                     11|                   12|Stock Adjustment ...|\n",
      "|                     12|                   13|     Customer Contra|\n",
      "|                      0|                    0|             Missing|\n",
      "+-----------------------+---------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crea el registro para el id = 0\n",
    "tt_0 = [('0','0','Missing')]\n",
    "columns = ['ID_Tipo_transaccion_DWH','ID_Tipo_transaccion_T','Tipo']\n",
    "tt_0 = spark.createDataFrame(data=tt_0,schema=columns)\n",
    "tt = tt.union(tt_0)\n",
    "\n",
    "tt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9Oou0g986vy"
   },
   "source": [
    "#### Carga\n",
    "Una vez realizado esto, se guardan los resultados en la base de datos destino\n",
    "\n",
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qICUWYCa86vy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, tt,'Estudiante_58_202413.TipoTransaccion', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6k37LtO86vy",
    "tags": []
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 3\n",
    "Empezamos el bloque 3: dimensión Producto. Su fuente de datos es la tabla <i>Producto</i>. De esta tabla solo se general los Ids y un nombre para la tabla de hechos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|ID_producto|      NombreProducto|\n",
      "+-----------+--------------------+\n",
      "|          1|USB missile launc...|\n",
      "|          2|USB rocket launch...|\n",
      "|          3|Office cube peris...|\n",
      "|          4|USB food flash dr...|\n",
      "|          5|USB food flash dr...|\n",
      "|          6|USB food flash dr...|\n",
      "|          7|USB food flash dr...|\n",
      "|          8|USB food flash dr...|\n",
      "|          9|USB food flash dr...|\n",
      "|         10|USB food flash dr...|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_prod = '''(SELECT DISTINCT `ID_producto`, NombreProducto  FROM WWImportersTransactional.Producto ) AS Temp_prod'''\n",
    "prod = obtener_dataframe_de_bd(source_db_connection_string, sql_prod, db_user, db_psswd)\n",
    "prod.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+\n",
      "|ID_Producto_DWH|ID_Producto_T|              Nombre|\n",
      "+---------------+-------------+--------------------+\n",
      "|              1|            1|USB missile launc...|\n",
      "|              2|            2|USB rocket launch...|\n",
      "|              3|            3|Office cube peris...|\n",
      "|              4|            4|USB food flash dr...|\n",
      "|              5|            5|USB food flash dr...|\n",
      "|              6|            6|USB food flash dr...|\n",
      "|              7|            7|USB food flash dr...|\n",
      "|              8|            8|USB food flash dr...|\n",
      "|              9|            9|USB food flash dr...|\n",
      "|             10|           10|USB food flash dr...|\n",
      "|             11|           11|USB food flash dr...|\n",
      "|             12|           12|USB food flash dr...|\n",
      "|             13|           13|USB food flash dr...|\n",
      "|             14|           14|USB food flash dr...|\n",
      "|             15|           15|USB food flash dr...|\n",
      "|             16|           16|DBA joke mug - mi...|\n",
      "|             17|           17|DBA joke mug - mi...|\n",
      "|             18|           18|DBA joke mug - da...|\n",
      "|             19|           19|DBA joke mug - da...|\n",
      "|             20|           20|DBA joke mug - yo...|\n",
      "+---------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombro columnas y creo ID_Producto_DWH\n",
    "prod = prod.selectExpr('ID_producto as ID_Producto_T', 'NombreProducto as Nombre')\n",
    "prod = prod.coalesce(1).withColumn('ID_Producto_DWH', f.monotonically_increasing_id() + 1)\n",
    "prod = prod.select('ID_Producto_DWH','ID_Producto_T', 'Nombre').distinct()\n",
    "\n",
    "# Crea el registro para el id = 0\n",
    "prod_0 = [('0','0','Missing')]\n",
    "columns = ['ID_Producto_DWH','ID_Producto_T','Nombre']\n",
    "prod_0 = spark.createDataFrame(data=prod_0,schema=columns)\n",
    "prod = prod.union(prod_0)\n",
    "\n",
    "prod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Una vez realizado esto, se guardan los resultados en la base de datos destino\n",
    "\n",
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, prod,'Estudiante_58_202413.Producto', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 4\n",
    "Empezamos el bloque 4: dimensión Client. Su fuente de datos es la tabla <i>Clientes</i>. De esta tabla solo se general los Ids y un nombre para la tabla de hechos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|ID_Cliente|              Nombre|\n",
      "+----------+--------------------+\n",
      "|         1|Tailspin Toys (He...|\n",
      "|         2|Tailspin Toys (Sy...|\n",
      "|         3|Tailspin Toys (Pe...|\n",
      "|         4|Tailspin Toys (Me...|\n",
      "|         5|Tailspin Toys (Ga...|\n",
      "|         6|Tailspin Toys (Je...|\n",
      "|         7|Tailspin Toys (Fr...|\n",
      "|         8|Tailspin Toys (Bo...|\n",
      "|         9|Tailspin Toys (Ne...|\n",
      "|        10|Tailspin Toys (Wi...|\n",
      "+----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_cli = '''(SELECT DISTINCT `ID_Cliente`, `Nombre`  FROM WWImportersTransactional.Clientes) AS Temp_cli'''\n",
    "cli = obtener_dataframe_de_bd(source_db_connection_string, sql_cli, db_user, db_psswd)\n",
    "cli.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|              Nombre|\n",
      "+--------------+------------+--------------------+\n",
      "|             1|           1|Tailspin Toys (He...|\n",
      "|             2|           2|Tailspin Toys (Sy...|\n",
      "|             3|           3|Tailspin Toys (Pe...|\n",
      "|             4|           4|Tailspin Toys (Me...|\n",
      "|             5|           5|Tailspin Toys (Ga...|\n",
      "|             6|           6|Tailspin Toys (Je...|\n",
      "|             7|           7|Tailspin Toys (Fr...|\n",
      "|             8|           8|Tailspin Toys (Bo...|\n",
      "|             9|           9|Tailspin Toys (Ne...|\n",
      "|            10|          10|Tailspin Toys (Wi...|\n",
      "|            11|          11|Tailspin Toys (De...|\n",
      "|            12|          12|Tailspin Toys (Bi...|\n",
      "|            13|          13|Tailspin Toys (St...|\n",
      "|            14|          14|Tailspin Toys (Lo...|\n",
      "|            15|          15|Tailspin Toys (Ba...|\n",
      "|            16|          16|Tailspin Toys (Co...|\n",
      "|            17|          17|Tailspin Toys (Ea...|\n",
      "|            18|          18|Tailspin Toys (Go...|\n",
      "|            19|          19|Tailspin Toys (Le...|\n",
      "|            20|          20|Tailspin Toys (Co...|\n",
      "+--------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renombro columnas y creo ID_Producto_DWH\n",
    "cli = cli.selectExpr('ID_Cliente as ID_Cliente_T', 'Nombre')\n",
    "cli = cli.coalesce(1).withColumn('ID_Cliente_DWH', f.monotonically_increasing_id() + 1)\n",
    "cli = cli.select('ID_Cliente_DWH','ID_Cliente_T', 'Nombre').distinct()\n",
    "\n",
    "# Crea el registro para el id = 0\n",
    "cli_0 = [('0','0','Missing')]\n",
    "columns = ['ID_Cliente_DWH','ID_Cliente_T', 'Nombre']\n",
    "cli_0 = spark.createDataFrame(data=cli_0,schema=columns)\n",
    "cli = cli.union(cli_0)\n",
    "\n",
    "cli.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Carga\n",
    "Una vez realizado esto, se guardan los resultados en la base de datos destino\n",
    "\n",
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, cli,'Estudiante_58_202413.Cliente', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvj5E1GS86vz"
   },
   "source": [
    "### BLOQUE 5\n",
    "Empezamos el bloque 5: dimensión Proveedor. Su fuente de datos es la tabla <i>proveedoresCopia</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5kFkHTD86vz"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "FEW2mcMn86vz",
    "outputId": "a18be86c-fd81-4b56-de5c-bec1f41db118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+---------+------------------+---------+-------------+\n",
      "|ID_Proveedor|     NombreProveedor|Categoria|Contacto_principal|Dias_pago|Codigo_postal|\n",
      "+------------+--------------------+---------+------------------+---------+-------------+\n",
      "|           1| A Datum Corporation|        2|                21|      -14|        46077|\n",
      "|          16|A Datum Corporati...|        2|                21|       14|        46077|\n",
      "|           3|Consolidated Mess...|        6|                25|      -30|        94101|\n",
      "|           2|        Contoso Ltd.|        2|                23|       -7|        98253|\n",
      "|           4|       Fabrikam Inc.|        4|                27|       30|        40351|\n",
      "|          20|   Fabrikam Inc. Ltd|        4|                27|       30|        40351|\n",
      "|           5|Graphic Design In...|        2|                29|       14|        64847|\n",
      "|           6| Humongous Insurance|        9|                31|      -14|        37770|\n",
      "|           7|        Litware Inc.|        5|                33|       30|        95245|\n",
      "|          23|    Litware Inc. Ltd|        5|                33|       30|        95245|\n",
      "|           8|  Lucerne Publishing|        2|                35|      -30|        37659|\n",
      "|           9|      Nod Publishers|        2|                37|        7|        27906|\n",
      "|          10|Northwind Electri...|        3|                39|       30|         7860|\n",
      "|          25|Northwind Electri...|        3|                39|       30|         7860|\n",
      "|          12|   The Phone Company|        2|                43|       30|        56732|\n",
      "|          11|       Trey Research|        8|                41|       -7|        57543|\n",
      "|          26|   Trey Research Inc|        8|                41|        7|        57543|\n",
      "|          13|      Woodgrove Bank|        7|                45|        7|        94101|\n",
      "|          29|  Woodgrove Bank Ltd|        7|                45|        7|        94101|\n",
      "+------------+--------------------+---------+------------------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EXTRACCION\n",
    "sql_prov = '''(SELECT DISTINCT ProveedorID AS ID_Proveedor, NombreProveedor, CategoriaProveedorID AS Categoria, PersonaContactoPrincipalID AS Contacto_principal, DiasPago AS Dias_pago, CodigoPostal Codigo_postal FROM WWImportersTransactional.proveedoresCopia ORDER BY NombreProveedor) AS Temp_prov'''\n",
    "\n",
    "prov = obtener_dataframe_de_bd(source_db_connection_string, sql_prov, db_user, db_psswd)\n",
    "\n",
    "prov.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddFhEOmL86vz"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "8un2p4so86v0",
    "outputId": "ba2758d9-aca3-4198-c13c-514bdbf51061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+---------+------------------+---------+-------------+\n",
      "|ID_Proveedor_DWH|ID_Proveedor_T|              Nombre|Categoria|Contacto_principal|Dias_pago|Codigo_postal|\n",
      "+----------------+--------------+--------------------+---------+------------------+---------+-------------+\n",
      "|               9|             1| A Datum Corporation|        2|                21|       14|        46077|\n",
      "|              12|             3|Consolidated Mess...|        6|                25|       30|        94101|\n",
      "|               5|             2|        Contoso Ltd.|        2|                23|        7|        98253|\n",
      "|               8|             4|       Fabrikam Inc.|        4|                27|       30|        40351|\n",
      "|              11|             5|Graphic Design In...|        2|                29|       14|        64847|\n",
      "|               3|             6| Humongous Insurance|        9|                31|       14|        37770|\n",
      "|               4|             7|        Litware Inc.|        5|                33|       30|        95245|\n",
      "|              10|             8|  Lucerne Publishing|        2|                35|       30|        37659|\n",
      "|               7|             9|      Nod Publishers|        2|                37|        7|        27906|\n",
      "|              13|            10|Northwind Electri...|        3|                39|       30|         7860|\n",
      "|               1|            12|   The Phone Company|        2|                43|       30|        56732|\n",
      "|               2|            11|       Trey Research|        8|                41|        7|        57543|\n",
      "|               6|            13|      Woodgrove Bank|        7|                45|        7|        94101|\n",
      "|               0|             0|             Missing|         |                  |        0|             |\n",
      "+----------------+--------------+--------------------+---------+------------------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Normalizo Dias_pago\n",
    "prov = prov.withColumn(\"Dias_pago\", when(col(\"Dias_pago\") < 0, col(\"Dias_pago\") * -1).otherwise(col(\"Dias_pago\")))\n",
    "\n",
    "# Normalizo NombreProveedor y elimino duplicados\n",
    "prov = prov.withColumn(\"NombreN\", regexp_replace(col(\"NombreProveedor\"), r\"\\s*(Inc. Ltd|Inc|Ltd)\\.*\\s*$\", \"\"))\n",
    "window_spec = Window.partitionBy(\"NombreN\").orderBy(\"ID_Proveedor\")\n",
    "prov = prov.withColumn(\"Min_ID\", min_(\"ID_Proveedor\").over(window_spec))\n",
    "prov = prov.where(col(\"ID_Proveedor\") == col(\"Min_ID\")).drop(\"Min_ID\")\n",
    "\n",
    "# Renombro columnas y creo ID_Proveedor_DWH\n",
    "prov = prov.selectExpr('ID_Proveedor as ID_Proveedor_T', 'NombreProveedor as Nombre','Categoria','Contacto_principal','Dias_pago','Codigo_postal')\n",
    "prov = prov.coalesce(1).withColumn('ID_Proveedor_DWH', f.monotonically_increasing_id() + 1)\n",
    "prov = prov.select('ID_Proveedor_DWH','ID_Proveedor_T','Nombre','Categoria','Contacto_principal','Dias_pago','Codigo_postal').orderBy(col('Nombre'))\n",
    "\n",
    "# Crea el registro para el id = 0\n",
    "prov_0 = [('0','0','Missing', '','','0','')]\n",
    "columns = ['ID_Proveedor_DWH','ID_Proveedor_T','Nombre', 'Categoria','Contacto_principal','Dias_pago','Codigo_postal']\n",
    "prov_0 = spark.createDataFrame(data=prov_0,schema=columns)\n",
    "prov = prov.union(prov_0)\n",
    "\n",
    "prov.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuvVgJ4R86v0"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "yCC2zZqY86v0"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, prov,'Estudiante_58_202413.Proveedor', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fo-J97586v0"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HpgwA6t86v0"
   },
   "source": [
    "### BLOQUE 5\n",
    "Bloque 5: dimensión Fecha. Su fuente de datos es la tabla transaccional <i>movimientos_v2</i> campo <i>FechaTransaccion</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZjDeVYd86v1"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "2HTzU96W86v1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|FechaTransaccion|\n",
      "+----------------+\n",
      "|     Jan 20,2014|\n",
      "|     Jan 28,2014|\n",
      "|     Feb 01,2014|\n",
      "|     Mar 25,2014|\n",
      "|     May 01,2014|\n",
      "|     May 02,2014|\n",
      "|     May 10,2014|\n",
      "|     May 26,2014|\n",
      "|     Jun 02,2014|\n",
      "|     Jul 08,2014|\n",
      "|     Jul 17,2014|\n",
      "|     Jul 24,2014|\n",
      "|     Aug 19,2014|\n",
      "|     Sep 16,2014|\n",
      "|     Sep 17,2014|\n",
      "|     Sep 23,2014|\n",
      "|     Oct 04,2014|\n",
      "|     Oct 21,2014|\n",
      "|     Oct 30,2014|\n",
      "|     Nov 07,2014|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EXTRACCION\n",
    "sql_fechas = '''(SELECT DISTINCT FechaTransaccion FROM WWImportersTransactional.movimientos_v2) AS Temp_Fechas'''\n",
    "fechas = obtener_dataframe_de_bd(source_db_connection_string, sql_fechas, db_user, db_psswd)\n",
    "fechas.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7xbgfCk86v1"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "97vmyl3Q86v1",
    "outputId": "0ffd3364-9b73-4001-e9bf-de53c97a2b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+---+----+-----------------+\n",
      "|  ID_Fecha|     Fecha|Dia|Mes|Anio|Numero_semana_ISO|\n",
      "+----------+----------+---+---+----+-----------------+\n",
      "|1357016400|2013-01-01|  1|  1|2013|                1|\n",
      "|1357102800|2013-01-02|  2|  1|2013|                1|\n",
      "|1357189200|2013-01-03|  3|  1|2013|                1|\n",
      "|1357275600|2013-01-04|  4|  1|2013|                1|\n",
      "|1357362000|2013-01-05|  5|  1|2013|                1|\n",
      "|1357534800|2013-01-07|  7|  1|2013|                2|\n",
      "|1357621200|2013-01-08|  8|  1|2013|                2|\n",
      "|1357707600|2013-01-09|  9|  1|2013|                2|\n",
      "|1357794000|2013-01-10| 10|  1|2013|                2|\n",
      "|1357880400|2013-01-11| 11|  1|2013|                2|\n",
      "|1357966800|2013-01-12| 12|  1|2013|                2|\n",
      "|1358139600|2013-01-14| 14|  1|2013|                3|\n",
      "|1358226000|2013-01-15| 15|  1|2013|                3|\n",
      "|1358312400|2013-01-16| 16|  1|2013|                3|\n",
      "|1358398800|2013-01-17| 17|  1|2013|                3|\n",
      "|1358485200|2013-01-18| 18|  1|2013|                3|\n",
      "|1358571600|2013-01-19| 19|  1|2013|                3|\n",
      "|1358744400|2013-01-21| 21|  1|2013|                4|\n",
      "|1358830800|2013-01-22| 22|  1|2013|                4|\n",
      "|1358917200|2013-01-23| 23|  1|2013|                4|\n",
      "+----------+----------+---+---+----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encuentro las que no cumplen el formato pautado\n",
    "regex = \"([0-2]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1]))\"\n",
    "cumplenFormato = fechas.filter(fechas[\"FechaTransaccion\"].rlike(regex))\n",
    "noCumplenFormato = fechas.filter(~fechas[\"FechaTransaccion\"].rlike(regex))\n",
    "\n",
    "# Las corrijo\n",
    "noCumplenFormato = noCumplenFormato.withColumn('FechaTransaccion', f.udf(lambda d: datetime.strptime(d, '%b %d,%Y').strftime('%Y-%m-%d 12:00:00.0000000'), t.StringType())(f.col('FechaTransaccion')))\n",
    "fechas_ok = noCumplenFormato.union(cumplenFormato)\n",
    "\n",
    "# Desgloso la fecha como exige la dimensión\n",
    "fechas_ok = fechas_ok.withColumn(\n",
    "    \"FechaTransaccion\", \n",
    "    to_timestamp(\"FechaTransaccion\", \"yyyy-MM-dd HH:mm:ss.SSSSSSS\")\n",
    ")\n",
    "fechas_ok = fechas_ok.withColumn(\"Fecha\", to_date(\"FechaTransaccion\")) \\\n",
    "       .withColumn(\"Dia\", date_format(\"FechaTransaccion\", \"d\"))  \\\n",
    "       .withColumn(\"Mes\", date_format(\"FechaTransaccion\", \"M\")) \\\n",
    "       .withColumn(\"Anio\", date_format(\"FechaTransaccion\", \"yyyy\")) \\\n",
    "       .withColumn(\"Numero_semana_ISO\", weekofyear(\"FechaTransaccion\"))\n",
    "\n",
    "fechas_ok = fechas_ok.withColumn(\"ID_Fecha\", unix_timestamp(\"Fecha\"))\n",
    "fechas_ok = fechas_ok.select('ID_Fecha', 'Fecha', 'Dia', 'Mes', 'Anio', 'Numero_semana_ISO').distinct().orderBy('ID_Fecha')\n",
    "\n",
    "fechas_ok.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh_102Yy86v1"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "UpbxgpWn86v1"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, fechas_ok,'Estudiante_58_202413.Fecha', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTy1oE3V86v2"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ocmdLWv86v4"
   },
   "source": [
    "### BLOQUE 6\n",
    "Bloque 6: Hecho orden. Su fuente de datos es la combinación entre las tablas transaccionales Ordenes y detalles de orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvgnsPfK86v4"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "9b4Qs9_886v4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+------------+---------------------+--------+\n",
      "|FechaTransaccion|ID_Producto_T|ID_Proveedor_T|ID_Cliente_T|ID_Tipo_transaccion_T|Cantidad|\n",
      "+----------------+-------------+--------------+------------+---------------------+--------+\n",
      "|     Jan 20,2014|          108|          null|       185.0|                   10|   -10.0|\n",
      "|     Jan 28,2014|          162|           4.0|         0.0|                   11|    10.0|\n",
      "|     Jan 28,2014|          216|          null|       474.0|                   10|   -10.0|\n",
      "|     Jan 28,2014|           22|           7.0|         0.0|                   11|    10.0|\n",
      "|     Jan 28,2014|           25|           7.0|         0.0|                   11|    10.0|\n",
      "+----------------+-------------+--------------+------------+---------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prod = obtener_dataframe_de_bd(source_db_connection_string, '''(SELECT ID_Producto_DWH, ID_Producto_T FROM Estudiante_58_202413.Producto) AS Temp_prod''', db_user, db_psswd)\n",
    "prov = obtener_dataframe_de_bd(source_db_connection_string, '''(SELECT ID_Proveedor_DWH, ID_Proveedor_T FROM Estudiante_58_202413.Proveedor) AS Temp_prov''', db_user, db_psswd)\n",
    "cli = obtener_dataframe_de_bd(source_db_connection_string, '''(SELECT ID_Cliente_DWH, ID_Cliente_T FROM Estudiante_58_202413.Cliente) AS Temp_cli''', db_user, db_psswd)\n",
    "tt = obtener_dataframe_de_bd(source_db_connection_string, '''(SELECT ID_Tipo_transaccion_DWH, ID_Tipo_transaccion_T FROM Estudiante_58_202413.TipoTransaccion) AS Temp_tt''', db_user, db_psswd)\n",
    "mov = obtener_dataframe_de_bd(source_db_connection_string, '''(SELECT DISTINCT FechaTransaccion, ProductoID as ID_Producto_T, ProveedorID as ID_Proveedor_T, ClienteID as ID_Cliente_T, TipoTransaccionID as ID_Tipo_transaccion_T, Cantidad FROM WWImportersTransactional.movimientos_v2) AS Temp_mov''', db_user, db_psswd)\n",
    "\n",
    "\n",
    "mov.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTv_CIOT86v5"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcHdgPzj86v5"
   },
   "source": [
    "Se hace una verificación de los valores de la tasa de impuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "GT5i7Yjq86v5",
    "outputId": "95819129-618e-4d35-dd6b-878ea1f88ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+----------------+--------------+-----------------------+--------+\n",
      "|  ID_Fecha|ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_transaccion_DWH|Cantidad|\n",
      "+----------+---------------+----------------+--------------+-----------------------+--------+\n",
      "|1407992400|             26|               0|            73|                      9|   -10.0|\n",
      "|1444194000|             29|               0|            66|                      9|   -10.0|\n",
      "|1460523600|             65|               0|           237|                      9|   -10.0|\n",
      "|1408942800|             65|               0|           440|                      9|    -6.0|\n",
      "|1389330000|             22|               0|           155|                      9|   -10.0|\n",
      "+----------+---------------+----------------+--------------+-----------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Realizo el join con las dimensiones\n",
    "mov_t = mov.join(prod, how = 'left', on = 'ID_Producto_T')\n",
    "mov_t = mov_t.join(prov, how = 'left', on = 'ID_Proveedor_T')\n",
    "mov_t = mov_t.join(cli, how = 'left', on = 'ID_Cliente_T')\n",
    "mov_t = mov_t.join(tt, how = 'left', on = 'ID_Tipo_transaccion_T')\n",
    "\n",
    "# Reemplazo las referencias vacías por 0\n",
    "mov_t = mov_t.fillna({'ID_Producto_DWH': 0, 'ID_Proveedor_DWH': 0, 'ID_Cliente_DWH': 0, 'ID_Tipo_transaccion_DWH': 0})\n",
    "\n",
    "# Corrijo y referencio las fechas\n",
    "regex = \"([0-2]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1]))\"\n",
    "cumplenFormato = mov_t.filter(mov_t[\"FechaTransaccion\"].rlike(regex))\n",
    "noCumplenFormato = mov_t.filter(~mov_t[\"FechaTransaccion\"].rlike(regex))\n",
    "noCumplenFormato = noCumplenFormato.withColumn('FechaTransaccion', f.udf(lambda d: datetime.strptime(d, '%b %d,%Y').strftime('%Y-%m-%d 12:00:00.0000000'), t.StringType())(f.col('FechaTransaccion')))\n",
    "mov_t = noCumplenFormato.union(cumplenFormato)\n",
    "mov_t = mov_t.withColumn(\"FechaTransaccion\", to_timestamp(\"FechaTransaccion\", \"yyyy-MM-dd HH:mm:ss.SSSSSSS\")) \\\n",
    "    .withColumn(\"Fecha\", to_date(\"FechaTransaccion\")) \\\n",
    "    .withColumn(\"ID_Fecha\", unix_timestamp(\"Fecha\"))\n",
    "\n",
    "mov_t = mov_t.selectExpr('ID_Fecha','ID_Producto_DWH','ID_Proveedor_DWH','ID_Cliente_DWH','ID_Tipo_transaccion_DWH','Cantidad').distinct()\n",
    "\n",
    "mov_t.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI27nmvB86v5"
   },
   "source": [
    "Se hace una verificación del rango de fechas disponible en los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9f10qpB86v9"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, mov_t,'Estudiante_58_202413.Hecho_Movimiento', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXk0Fxmu86v9"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWmcDXue86v9"
   },
   "source": [
    "# Resultado de consultas\n",
    "Corresponde a las consultas realizadas sobre las tablas, para mostrar el estado final de las tablas pobladas como resultado del proceso de ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGMlLaje86v9"
   },
   "source": [
    "# 3. Tarea ETL\n",
    "Espacio para desarrollar la tarea planteada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwyeLpt386v9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euvEeguv86v9"
   },
   "source": [
    "## 4. Cierre\n",
    "Completado este tutorial, ya sabe cómo realizar ETL básicos en PySpark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaFNpgeW86v9"
   },
   "source": [
    "## 5. Información adicional\n",
    "\n",
    "Si quiere conocer más sobre PySpark la guía más detallada es la documentación oficial, la cual puede encontrar acá: https://spark.apache.org/docs/latest/api/python/index.html <br>\n",
    "Para ir directamente a la documentación de PySpark SQL, donde está la información sobre los DataFrames, haga clic en este enlace: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html <br>\n",
    "\n",
    "El Capítulo 2 del libro <i>Learn PySpark : Build Python-based Machine Learning and Deep Learning Models, New York: Apress. 2019</i> de Pramod Singh contiene muchos ejemplos útiles, puede encontrarlo en la biblioteca virtual de la universidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kIcwffv86v-"
   },
   "source": [
    "## 6. Preguntas frecuentes\n",
    "\n",
    "- Si al intentar escribir un <i>dataframe</i> obtiene un error en el formato: \n",
    "    ```\n",
    "    path file:<PATH>/dw/<PATH> already exists.;\n",
    "    ```\n",
    "    Borre la carpeta indicada en el error y vuelva a intentar.\n",
    "\n",
    "- Si al ejecutar su código obtiene el error: \n",
    "    ```\n",
    "    ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=tutorial ETL PySpark, master=local) created by __init__ at <ipython-input-4-64455da959dd>:92 \n",
    "\n",
    "    ```\n",
    "    reinicie el kernel del notebook y vuelva a intentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6J9jYwEJ86v-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vtE61qk986vx",
    "X9Oou0g986vy",
    "B5kFkHTD86vz",
    "ddFhEOmL86vz",
    "MuvVgJ4R86v0",
    "BZjDeVYd86v1",
    "_7xbgfCk86v1",
    "Rh_102Yy86v1",
    "HogvCqW_86v2",
    "9rKmT9jd86v2",
    "R9SnkMUH86v3",
    "k8O1GvOd86v3",
    "Mo633Vpg86v3",
    "i36NawhX86v4",
    "LvgnsPfK86v4",
    "dTv_CIOT86v5",
    "N9f10qpB86v9"
   ],
   "name": "MISW-ETL-TutorialETL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
